# Execution Mode
# Options: 'daily' (runs celery beat), 'on-demand' (runs api server)
ANALYTICS_EXECUTION_MODE=on-demand

# API Configuration
API_HOST=0.0.0.0
API_PORT=8001

# ClickHouse Connection
CLICKHOUSE_HOST=localhost
CLICKHOUSE_PORT=8423
CLICKHOUSE_USER=default
CLICKHOUSE_PASSWORD=password1234
CLICKHOUSE_DATABASE=default
# Base DB for connection, pipeline creates analytics_{network}

# Celery Configuration
# Use REDIS_URL for unified config or split if needed
REDIS_URL=redis://localhost:6379/0
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/0

# Logging
LOG_LEVEL=INFO

# ===================
# Benchmark Configuration
# ===================

# Validator ClickHouse (uses default database)
VALIDATOR_CH_HOST=localhost
VALIDATOR_CH_PORT=9000
VALIDATOR_CH_DATABASE=default

# Network-specific Data Pipelines
TORUS_DATA_PIPELINE_CH_HOST=torus-pipeline-clickhouse
TORUS_DATA_PIPELINE_CH_PORT=9000
TORUS_DATA_PIPELINE_CH_DATABASE=pipeline

BITTENSOR_DATA_PIPELINE_CH_HOST=bittensor-pipeline-clickhouse
BITTENSOR_DATA_PIPELINE_CH_PORT=9000
BITTENSOR_DATA_PIPELINE_CH_DATABASE=pipeline

# Benchmark Settings
BENCHMARK_REPOS_PATH=/var/benchmark/repos
BENCHMARK_DATA_PATH=/var/benchmark/data
BENCHMARK_MAX_EXECUTION_TIME=3600
BENCHMARK_EPOCH_DAYS=7
BENCHMARK_MEMORY_LIMIT=32g

# Docker Configuration
DOCKER_HOST=unix:///var/run/docker.sock
BENCHMARK_BASE_IMAGES=python:3.11-slim,nvidia/cuda:12.1-runtime-ubuntu22.04

# S3 Configuration (for test datasets)
SYNTHETICS_S3_ENDPOINT=https://s3.amazonaws.com
SYNTHETICS_S3_BUCKET=your-bucket
SYNTHETICS_S3_ACCESS_KEY=your-access-key
SYNTHETICS_S3_SECRET_KEY=your-secret-key
SYNTHETICS_S3_REGION=us-east-1